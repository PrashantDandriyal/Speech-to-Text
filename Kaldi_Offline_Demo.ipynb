{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaldi_OpenDevLibrary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNNs504vyZoD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QIdgwxSYHxE",
        "colab_type": "text"
      },
      "source": [
        "###Install OpenVINO toolkit and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5pa8HAQSelr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/alihussainia/OpenDevLibrary/master/openvino_initialization_script.py\"\n",
        "!python openvino_initialization_script.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YijAbaNCYZJ1",
        "colab_type": "text"
      },
      "source": [
        "###Download model files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYLQSxDyVkwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --force-html  -i \"https://download.01.org/openvinotoolkit/models_contrib/speech/kaldi/wsj_dnn5b_smbr/\" -P \"/content/model_files\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVMJG0KIYdy2",
        "colab_type": "text"
      },
      "source": [
        "###Convert model to IR format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYvqp5ZfVtVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model /content/model_files/wsj_dnn5b.nnet --counts /content/model_files/wsj_dnn5b.counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3iFqQYJcBCe",
        "colab_type": "text"
      },
      "source": [
        "###Convert WAV file to input feature containing ARK file using the [docs](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_kaldi_specific_Aspire_Tdnn_Model.html) here.\n",
        "\n",
        "\n",
        "\n",
        "1.   Download a Kaldi repository. \n",
        "2.   Build it using instructions in README.md in the repository.\n",
        "    \n",
        "    2.1. Go to *tools/*  and follow INSTALL instructions there.\n",
        "\n",
        "    2.2. Go to *src/* and follow INSTALL instructions there.\n",
        "3.  Prepare Data (Convert .wav file to .ark) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U4nAGtu8A-g",
        "colab_type": "text"
      },
      "source": [
        "###1.   Download a Kaldi repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv2pcYb1XDse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone \"https://github.com/kaldi-asr/kaldi.git\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCjkqBbJ8GVN",
        "colab_type": "text"
      },
      "source": [
        "###2. Build it using instructions in README.md in the repository.\n",
        "\n",
        "The instructions for the LINUX version, as per the README, can be found [HERE](https://github.com/kaldi-asr/kaldi/blob/master/tools/INSTALL)\n",
        "\n",
        "First, change the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReQ_3BWgIII9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/kaldi/tools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBGHmT1cH2C5",
        "colab_type": "text"
      },
      "source": [
        "####2.1 Go to *tools/*  and follow INSTALL instructions there.\n",
        "\n",
        "2.1.1 Run *check_dependencies.sh*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-igavFk8eTAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!extras/check_dependencies.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "andmyFAa_i5u",
        "colab_type": "text"
      },
      "source": [
        "###Missing packages are manually installed below, depending on the output of the above cell, until the *check_dependencies.sh* returns **all OK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AktB0QaC_lB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install sox subversion #Asked to be installed by output\n",
        "!/content/kaldi/tools/extras/install_mkl.sh #Asked to be installed by output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNUoUW14zfc7",
        "colab_type": "code",
        "outputId": "72aa79cb-aef1-40df-b6f4-d4357d86399a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!extras/check_dependencies.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extras/check_dependencies.sh: all OK.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJHfRfrSHpDK",
        "colab_type": "text"
      },
      "source": [
        "2.1.2 Run Make\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMKcovYPzo9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!make -j 4 #Using multiple CPUs as it Takes a LONG time to run. \n",
        "#Replace with simply \"!make\" if an error is logged."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn6fuF6WM9wX",
        "colab_type": "text"
      },
      "source": [
        "2.2. Go to *src/* and follow INSTALL instructions there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILk6VQwb0fQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/kaldi/src\n",
        "!./configure --shared\n",
        "!make depend -j 8\n",
        "!make -j 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvAApO_qL1Ih",
        "colab_type": "text"
      },
      "source": [
        "###Downloading reduired files\n",
        "- Intel Models\n",
        "- Create configuration file\n",
        "- Required pre-requisites for LibriSpeech Model\n",
        "- Related Model files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TdYLc4MxrHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/blowup.wav\" \"/opt/intel/openvino_2020.1.023/deployment_tools/demo/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMYJ5M_49TD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/opt/intel/openvino_2020.1.023/deployment_tools/demo/demo_speech_recognition.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wth8Takp4gHe",
        "colab_type": "text"
      },
      "source": [
        "###Running Offline DEMO \n",
        "*(To use it for custom WAV file, replace the \"run_demo.sh\" file and add the path to your file)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHXnrFW-3a2H",
        "colab_type": "code",
        "outputId": "03290548-0138-45db-ba91-c9a97c8a48e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!/opt/intel/openvino/data_processing/audio/speech_recognition/demos/offline_speech_recognition_demo/run_demo.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[setupvars.sh] OpenVINO environment initialized\n",
            "target_precision = FP32\n",
            "Using model configuration file /root/openvino_models/ir/intel/lspeech_s5_ext/FP32/speech_lib.cfg\n",
            "Run Inference Engine offline speech recognition demo\n",
            "\n",
            "\tlinux-vdso.so.1 (0x00007ffc98168000)\n",
            "\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4 (0x00007f4b6d557000)\n",
            "\tlibspeech_library.so => /root/data_processing_demos_build/audio/speech_recognition/intel64/Release/lib/libspeech_library.so (0x00007f4b6d331000)\n",
            "\tlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f4b6d112000)\n",
            "\tlibstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f4b6cd89000)\n",
            "\tlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f4b6cb71000)\n",
            "\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f4b6c780000)\n",
            "\tlibunwind.so.8 => /usr/lib/x86_64-linux-gnu/libunwind.so.8 (0x00007f4b6c565000)\n",
            "\tlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f4b6c1c7000)\n",
            "\tlibinference_engine.so => /opt/intel/openvino_2020.1.023/deployment_tools/inference_engine/lib/intel64/libinference_engine.so (0x00007f4b6bb51000)\n",
            "\tlibfeature_extraction_library.so => /opt/intel/openvino/data_processing/audio/speech_recognition/demos/offline_speech_recognition_demo/../../../../../data_processing/audio/speech_recognition/lib/x64/libfeature_extraction_library.so (0x00007f4b6b93f000)\n",
            "\tlibdecoder_library.so => /opt/intel/openvino/data_processing/audio/speech_recognition/demos/offline_speech_recognition_demo/../../../../../data_processing/audio/speech_recognition/lib/x64/libdecoder_library.so (0x00007f4b6b6f7000)\n",
            "\t/lib64/ld-linux-x86-64.so.2 (0x00007f4b6d9d0000)\n",
            "\tliblzma.so.5 => /lib/x86_64-linux-gnu/liblzma.so.5 (0x00007f4b6b4d1000)\n",
            "\tlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f4b6b2cd000)\n",
            "\tlibtbb.so.2 => /opt/intel/openvino_2020.1.023/deployment_tools/inference_engine/external/tbb/lib/libtbb.so.2 (0x00007f4b6b069000)\n",
            "\tlibngraph.so => /opt/intel/openvino_2020.1.023/deployment_tools/ngraph/lib/libngraph.so (0x00007f4b6a825000)\n",
            "\tlibrt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f4b6a61d000)\n",
            "Run ./offline_speech_recognition_app -wave=/opt/intel/openvino/data_processing/audio/speech_recognition/demos/offline_speech_recognition_demo/../../../../../deployment_tools/demo/how_are_you_doing.wav -c=/root/openvino_models/ir/intel/lspeech_s5_ext/FP32/speech_lib.cfg\n",
            "\n",
            "[ INFO ] Using feature transformation /root/openvino_models/ir/intel/lspeech_s5_ext/FP32/lspeech_s5_ext.feature_transform\n",
            "[ INFO ] InferenceEngine API ver. 2.1 (build: 37988)\n",
            "[ INFO ] Device info:\n",
            "[ INFO ] \tCPU: MKLDNNPlugin ver. 2.1\n",
            "[ INFO ] Batch size: 8\n",
            "[ INFO ] Model loading time: 47.21 ms\n",
            "Recognition result:\n",
            "HOW ARE YOU DOING\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4eMPJZn5zOX",
        "colab_type": "code",
        "outputId": "9cc1620b-16a0-45f9-d0d7-42c406469be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /opt/intel/openvino_2020.1.023/deployment_tools/ngraph/lib/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "libngraph.so\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}